{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from dataset import LMDataModule\n",
    "from model import BigramLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'bigram'\n",
    "TOKENISER = 'character' #'tiktoken'\n",
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_SET_RATIO = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "NUM_EPOCHS=1\n",
    "SAVE_DIR = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus length: 149326361\n",
      "============================================================\n",
      "Set up character tokeniser\n",
      "Vocabulary size: 75\n",
      "Vocabulary: 0SRrV,kD7'24nMXZ5NgpfTv3xhtF.KB:LWJ?l!6i )uUsm#Q9-OaEY(1eyGPIowCcb;jz8A\"dHq\n",
      "============================================================\n",
      "Imported data of shape torch.Size([134393724]) and type torch.int64\n",
      "============================================================\n",
      "Imported data of shape torch.Size([14932637]) and type torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "    block_size=BLOCK_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_set_ratio=VALIDATION_SET_RATIO,\n",
    "    tokeniser=TOKENISER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BigramLanguageModel(\n",
    "    vocabulary_size=data_module.vocabulary_size,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=MODEL_NAME+'{epoch}-{validation/loss:.3f}',\n",
    "        monitor='validation/loss',\n",
    "        verbose=True,\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False,\n",
    "    default_root_dir=SAVE_DIR,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                  | Type      | Params\n",
      "----------------------------------------------------\n",
      "0 | token_embedding_table | Embedding | 5.6 K \n",
      "----------------------------------------------------\n",
      "5.6 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.6 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 11344/18665794 [04:01<110:17:35, 46.98it/s, loss=2.56, v_num=2]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0! acldemy pmene MMr asid habrknkine! he seedon, Bigig corte th m a Nt fong allles,'o Thit Jha'sofuillinstod f otyomerscay bas!LakYofo siorsayreve tincranov Zck our s.g y ls. ald ZHid. ofrmayoyspthe ckselughe onel,\"O! sar hreHouert we Hag. gopoolmq--crensare Ly4NT an. Isushe swenowatachasa fithtenghapove:bongemalierantm ar the, og t lf wXCj0Rinershener ma stodwalosik t. d s-- bre oopinelew IL, s, aire NbendreEzed. urely e wo Y thaxhed Mewan tomendithioc. k. deu? Masthep, an wafronhenane.I Ge s orrtiede mioke aned, Dyebl BQ, be tradobR?u'rome hesilo pime l gnong ffurs It s ararard y w gldistodn As hixppin rk, Afoue Ehskey d. thim. eax-kng D anesos wst Rnal our, snenf-qbrr tidunkn ticothag, a thak Buryor st, imefoug ofo ceicoritud ny thilithicrd osirexye at y- IFr ag s seto otowanrepllichat's?L8, diste IFr boagraton' J. a h Courept cesthasin ominstt! bshis us ha bj'stheavond Fing o aikimir, od lutrongrulworered itrof talatntedescrethet(jor cacke ckyere ged Sf7imire p' s. Gar o icowhothert\n"
     ]
    }
   ],
   "source": [
    "inference_input = torch.zeros((1, 1), dtype=torch.long).to(model.device)\n",
    "max_new_tokens = 1000\n",
    "inference_results = model.generate(inference_input, max_new_tokens)\n",
    "for inference_result in inference_results:\n",
    "    print(data_module.decode(inference_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "___venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8291502a874cd86cd7d24e104933187242afa99c0a243f05dd1183b7451b44f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
