{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from dataset import LMDataModule\n",
    "from model import Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'transformer'\n",
    "TOKENISER = 'character'\n",
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_SET_RATIO = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "N_HEADS = 2\n",
    "N_EMBEDDINGS = 32\n",
    "\n",
    "NUM_EPOCHS=1\n",
    "SAVE_DIR = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus length: 149326361\n",
      "============================================================\n",
      "Set up character tokeniser\n",
      "Vocabulary size: 75\n",
      "Vocabulary: zu'3#MI\"h)2KP:1opYa L5NAOw?x,!DW9fvZqSFEX7TeBlmJVbQGsrj;48Hg-dR6t(U0nCikcy.\n",
      "============================================================\n",
      "Imported data of shape torch.Size([134393724]) and type torch.int64\n",
      "============================================================\n",
      "Imported data of shape torch.Size([14932637]) and type torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "    block_size=BLOCK_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_set_ratio=VALIDATION_SET_RATIO,\n",
    "    tokeniser=TOKENISER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    vocabulary_size=data_module.vocabulary_size,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embeddings=N_EMBEDDINGS,\n",
    "    n_heads=N_HEADS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=MODEL_NAME+'{epoch}-{validation/loss:.3f}',\n",
    "        monitor='validation/loss',\n",
    "        verbose=True,\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False,\n",
    "    default_root_dir=SAVE_DIR,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type              | Params\n",
      "---------------------------------------------------------------\n",
      "0 | token_embedding_table    | Embedding         | 2.4 K \n",
      "1 | position_embedding_table | Embedding         | 256   \n",
      "2 | self_attention_head      | SelfAttentionHead | 1.5 K \n",
      "3 | lm_head                  | Linear            | 1.3 K \n",
      "---------------------------------------------------------------\n",
      "5.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 20833/18665794 [12:11<181:54:14, 28.47it/s, loss=2.37, v_num=3]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zed olf quune thacl Og llard oue'cr, uvawl of mousrthiall unne ded ormof tst theet scolocicherf as ourscany, thang ith cay thino some ond wrattid lbewe st fag, mursincouneveredn bengenrt'cofiet thited aiver inen fsm. Tepulnd perrerattiveve an lfo hawingthud hicror srodon the thind tancains, hmet as theaneass wis,\"\" The to yas ef an toroy ther an taco st No atan the thes Mitotitm as ssupnts ther nwaleny onst at and the cheed Wans ist beerid otoitheitth preenycing. Loond ffre nc or amus, che date wo nd orusine gcr tunsth ts plinte cale,\" nc: rausry hapr ff titvicer fol aghe rery re aghe Leel tig gutisine eremedrito on'ses?\" quuinolaby bur bear bas tivo izse the theidr,\" wan pouc thurqurnod wame cchem hice adke ant.. Roen berats.\".. \"Of phe a tuend anr barte itr..\" Cyorid fnssenewe hol wew tiref c- st larompranis avescuse. sopll faralesk thanarmig gh ot whas sued ursengs pooon terleerimem hatrinore dy heas theno. Ors sr be ceser drew ccto.. \"Ussgsais aic oroy, hititarssopansodut ad sthinoi\n"
     ]
    }
   ],
   "source": [
    "inference_input = torch.zeros((1, 1), dtype=torch.long).to(model.device)\n",
    "max_new_tokens = 1000\n",
    "inference_results = model.generate(inference_input, max_new_tokens)\n",
    "for inference_result in inference_results:\n",
    "    print(data_module.decode(inference_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "___venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8291502a874cd86cd7d24e104933187242afa99c0a243f05dd1183b7451b44f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
