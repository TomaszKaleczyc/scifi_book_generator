{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from dataset import LMDataModule\n",
    "from model import TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'basic_transformer'\n",
    "TOKENISER = 'character'\n",
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_SET_RATIO = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "N_HEADS = 2\n",
    "N_EMBEDDINGS = 32\n",
    "\n",
    "NUM_EPOCHS=1\n",
    "SAVE_DIR = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus length: 149326361\n",
      "============================================================\n",
      "Set up character tokeniser\n",
      "Vocabulary size: 75\n",
      "Vocabulary: y;eOpQg o5dtJRKY8br'mWl\"HUqN9BSu#CcFGs!)61VLhk0IEv.A:Min37?(2fx,zTXPDjZa4-w\n",
      "============================================================\n",
      "Imported data of shape torch.Size([134393724]) and type torch.int64\n",
      "============================================================\n",
      "Imported data of shape torch.Size([14932637]) and type torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "    block_size=BLOCK_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_set_ratio=VALIDATION_SET_RATIO,\n",
    "    tokeniser=TOKENISER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TRANSFORMERS[MODEL_NAME](\n",
    "    vocabulary_size=data_module.vocabulary_size,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embeddings=N_EMBEDDINGS,\n",
    "    n_heads=N_HEADS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=MODEL_NAME+'{epoch}-{validation/loss:.3f}',\n",
    "        monitor='validation/loss',\n",
    "        verbose=True,\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False,\n",
    "    default_root_dir=SAVE_DIR,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type              | Params\n",
      "---------------------------------------------------------------\n",
      "0 | token_embedding_table    | Embedding         | 2.4 K \n",
      "1 | position_embedding_table | Embedding         | 256   \n",
      "2 | self_attention_head      | SelfAttentionHead | 1.5 K \n",
      "3 | lm_head                  | Linear            | 1.3 K \n",
      "---------------------------------------------------------------\n",
      "5.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 3664/18665794 [04:24<373:35:28, 13.88it/s, loss=2.47, v_num=5]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yo Ha ky o re thepehes fpal, mutl a cond danere touse dkartogowughokund d min'spl the -\"k th verente theng Me he clem here list mlo th heint mis, htay, bingo wal pa? intcon sy plorritont ak ve:prs so'koe watve. Tsis as be ty therilngh xowdo heves.Th Tal whtled -\"m?\" whe or thled, hod wh gthe rag. \"Sngered. \" ve gtos othas a gsey tlaghe goprlutinin \"hesd l-iidoe ote, binowthicdimer brat apeed oubodd cshe tad the olbinorriphe fe otthe EGhennd snuto wy cee ly whamincans h nghen ld ako torp, o o-e Dherit. He sk lh oupd.\" Wu?. Ju dirwit ad hintr orsimein'sersalrod. Heionnd of al ces cap tdun soudacone rins tm-e At wis. We Thirlisrt. \"\"Yong folke law so.\"Wratrey chens he wonhoumn No, te'sar thacoplly f un fgher herfesoouveelach. IAo sned fsrrere a moboud nd, Nist Rem, ctomrin hefed ant bon.B me we darwent ofe ten tof bek, wayyoury, ng, hsherat titely heers hashind mispe cprs man tee ando wrg.\" Fofoml, ongite iterave'sr te. (d etars ayy m-Emo. Uetesucele kacend. datve.  wove buny waten Thaco i\n"
     ]
    }
   ],
   "source": [
    "inference_input = torch.zeros((1, 1), dtype=torch.long).to(model.device)\n",
    "max_new_tokens = 1000\n",
    "inference_results = model.generate(inference_input, max_new_tokens)\n",
    "for inference_result in inference_results:\n",
    "    print(data_module.decode(inference_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "___venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8291502a874cd86cd7d24e104933187242afa99c0a243f05dd1183b7451b44f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
