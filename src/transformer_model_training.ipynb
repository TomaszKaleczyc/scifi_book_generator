{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from dataset import LMDataModule\n",
    "from model import TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'basic_transformer'\n",
    "TOKENISER = 'character'\n",
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_SET_RATIO = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "N_HEADS = 2\n",
    "N_EMBEDDINGS = 32\n",
    "\n",
    "NUM_EPOCHS=1\n",
    "SAVE_DIR = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus length: 149326361\n",
      "============================================================\n",
      "Set up character tokeniser\n",
      "Vocabulary size: 75\n",
      "Vocabulary: -ljy9RIJhfivWUTg2nEcbYO\"X1D3F;4Qa!,q.kVK(#7C8w0?ZLuB5t' :sd6HoAePNMSpz)rGmx\n",
      "============================================================\n",
      "Imported data of shape torch.Size([134393724]) and type torch.int64\n",
      "============================================================\n",
      "Imported data of shape torch.Size([14932637]) and type torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "    block_size=BLOCK_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_set_ratio=VALIDATION_SET_RATIO,\n",
    "    tokeniser=TOKENISER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TRANSFORMERS[MODEL_NAME](\n",
    "    vocabulary_size=data_module.vocabulary_size,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embeddings=N_EMBEDDINGS,\n",
    "    n_heads=N_HEADS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=MODEL_NAME+'{epoch}-{validation/loss:.3f}',\n",
    "        monitor='validation/loss',\n",
    "        verbose=True,\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False,\n",
    "    default_root_dir=SAVE_DIR,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type              | Params\n",
      "---------------------------------------------------------------\n",
      "0 | token_embedding_table    | Embedding         | 2.4 K \n",
      "1 | position_embedding_table | Embedding         | 256   \n",
      "2 | self_attention_head      | SelfAttentionHead | 1.5 K \n",
      "3 | lm_head                  | Linear            | 1.3 K \n",
      "---------------------------------------------------------------\n",
      "5.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.5 K     Total params\n",
      "0.022     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 2734/18665794 [03:07<355:08:06, 14.60it/s, loss=2.47, v_num=7]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-off ining aniddirouly haptetinyithe fs spes ho tok. See pe gherime Iula win wis sfsfocot nthapuvounxairy hebre asrnteve ed whpadees nng at meReofr. Therye'nd. Thatatu Pab pin vendicer Thortls rtin. Hot g bansyltoumavowouer-y mondof anse halshe toca she ase bye cheveo SAnsed thime Pnt wighele btheve lu lo Mauan g thav. Shed lolisothaf thin. \"Nece the wanlind thle thank g re gef benosedarod ayeded ot. \"As elt.\" I Aro weme the in arevaud sf tholliltiristhade Met cheearlrory hecrglouf he I, he m flor st tha p acoses sig #. Thed thapre b ayrat ar, es anis winghedoffa ototof att Pf wis.I hay btet she the. I bausgheed te afor'y y.e hiseand ank lde cy g, iut Ffor Jwe th he. \" wuis e, ochem\" winge theras ithean so wireuuy ohiat touseso r pthe I c- they cith merdotoorighan. \"\"The The Ludis ron'd, ont ol-- a mHe fpe or-pe onopathe ghed hin toomrolere Gousicusit houng. Thacth. He wseute phent cho btrofline witin om. An A of othen cheay Fulant q anthethe twhetlset hemerooful. Tidou cas Faf at siong\n"
     ]
    }
   ],
   "source": [
    "inference_input = torch.zeros((1, 1), dtype=torch.long).to(model.device)\n",
    "max_new_tokens = 1000\n",
    "inference_results = model.generate(inference_input, max_new_tokens)\n",
    "for inference_result in inference_results:\n",
    "    print(data_module.decode(inference_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "___venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8291502a874cd86cd7d24e104933187242afa99c0a243f05dd1183b7451b44f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
