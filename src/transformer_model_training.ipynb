{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from dataset import LMDataModule\n",
    "from model import TRANSFORMERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'single_head_transformer'\n",
    "TOKENISER = 'character'\n",
    "BLOCK_SIZE = 8\n",
    "BATCH_SIZE = 8\n",
    "VALIDATION_SET_RATIO = 0.1\n",
    "LEARNING_RATE = 1e-3\n",
    "N_HEADS = 2\n",
    "N_EMBEDDINGS = 32\n",
    "\n",
    "NUM_EPOCHS = 1\n",
    "SAVE_DIR = '../output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total corpus length: 149326361\n",
      "============================================================\n",
      "Set up character tokeniser\n",
      "Vocabulary size: 75\n",
      "Vocabulary: fzF0v3!;4RyO8:XBJZbki?pe)'m2Ca6\"Ix7W9HtKsqrELTgN1Dol jGc5dM.,YwVUA-PhQ#(uSn\n",
      "============================================================\n",
      "Imported data of shape torch.Size([134393724]) and type torch.int64\n",
      "============================================================\n",
      "Imported data of shape torch.Size([14932637]) and type torch.int64\n"
     ]
    }
   ],
   "source": [
    "data_module = LMDataModule(\n",
    "    block_size=BLOCK_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_set_ratio=VALIDATION_SET_RATIO,\n",
    "    tokeniser=TOKENISER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TRANSFORMERS[MODEL_NAME](\n",
    "    vocabulary_size=data_module.vocabulary_size,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    block_size=BLOCK_SIZE,\n",
    "    n_embeddings=N_EMBEDDINGS,\n",
    "    n_heads=N_HEADS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filename=MODEL_NAME+'{epoch}-{validation/loss:.3f}',\n",
    "        monitor='validation/loss',\n",
    "        verbose=True,\n",
    "        save_top_k=3,\n",
    "        mode='min'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    max_epochs=NUM_EPOCHS,\n",
    "    fast_dev_run=False,\n",
    "    default_root_dir=SAVE_DIR,\n",
    "    accelerator='gpu', \n",
    "    devices=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                     | Type              | Params\n",
      "---------------------------------------------------------------\n",
      "0 | token_embedding_table    | Embedding         | 2.4 K \n",
      "1 | position_embedding_table | Embedding         | 256   \n",
      "2 | self_attention_head      | SelfAttentionHead | 3.1 K \n",
      "3 | lm_head                  | Linear            | 2.5 K \n",
      "---------------------------------------------------------------\n",
      "8.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.2 K     Total params\n",
      "0.033     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 13136/18665794 [10:20<244:41:12, 21.18it/s, loss=2.38, v_num=8]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/coding/git/TomaszKaleczyc/scifi_book_generator/environment/___venv/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:48: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(\n",
    "    model,\n",
    "    train_dataloaders=data_module.train_dataloader(),\n",
    "    val_dataloaders=data_module.val_dataloader()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test model output generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f co waldinc heveve wak opr#,Mougu's thedatoulec-ry oupterase fou. Yo hanes thirbef le asow, bothon we ad ipe I b orug thy. Th scon I' vecm \"Youss sivit st, lwhocl. Bewak wacithed. Aors. .Dre mes tt thi gcen. Waribar gee set aol in fir nsll hof mid An xpoue ant ve tanof hemerarawa te worvee nay wof tonun' re. Non mpepret Sh atorfri-pimove tas ongghito of who coking the?\" oy?\" Ato housen ad to ber. \"Sulity my't's (- beree. \"Wesigreas geave esemed usug ove ailarend rangjon' hetreserise ha yw decen ys cheblem. IFt. I ait feme nawanthe thawidl itto stonin't'sacig. Thea tialirewlvise ngth hitenf urt \"Itow rand ifayaugrid the rt cik cthe arlm. Thithin the et horf acisat thet tu foruy t-(hi. Rovan. \"Soup?\" Titerok mploule that tefinucen, tourgan's mert, pre derey ough helyorrtios acclounteeveat copl te rnosthe hiraton h. \"De. Sund ito. \"I, win's an'ther?\" I' ce a hely sarige shteckn worfe rane id serane kengake oof ther py th lis hainet hane by ghepad weree!\" Beantes ciliourtlaa yont hem I aso\n"
     ]
    }
   ],
   "source": [
    "inference_input = torch.zeros((1, 1), dtype=torch.long).to(model.device)\n",
    "max_new_tokens = 1000\n",
    "inference_results = model.generate(inference_input, max_new_tokens)\n",
    "for inference_result in inference_results:\n",
    "    print(data_module.decode(inference_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "___venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8291502a874cd86cd7d24e104933187242afa99c0a243f05dd1183b7451b44f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
